{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import heapq as h\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, Embedding, LSTM, Dropout, add, Conv2D, AveragePooling2D, GlobalMaxPooling1D, concatenate\n",
    "from keras.layers import GRU, Flatten, Bidirectional, TimeDistributed, Concatenate, GlobalAveragePooling2D, RepeatVector, GlobalAveragePooling1D, BatchNormalization\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "start = \"\\033[1m\"; end = \"\\033[0;0m\"\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"\\033[1m\"; end = \"\\033[0;0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('padataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentence and word tokenizer\n",
    "s_tokenizer = RegexpTokenizer(r'[^?!]+')\n",
    "w_tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3259, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Indication</th>\n",
       "      <th>Findings</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Mesh</th>\n",
       "      <th>Image</th>\n",
       "      <th>View</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CXR101</td>\n",
       "      <td></td>\n",
       "      <td>chest pain</td>\n",
       "      <td>the heart is again mildly enlarged. mediastina...</td>\n",
       "      <td>1. mild stable cardiomegaly and central vascul...</td>\n",
       "      <td>cardiomegaly_mild,technical quality of image u...</td>\n",
       "      <td>CXR101_IM-0011-4004.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CXR1011</td>\n",
       "      <td></td>\n",
       "      <td>chronic</td>\n",
       "      <td>the heart is top normal in size. the mediastin...</td>\n",
       "      <td>no acute disease</td>\n",
       "      <td>normal</td>\n",
       "      <td>CXR1011_IM-0013-1001.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CXR1013</td>\n",
       "      <td></td>\n",
       "      <td>chest pain</td>\n",
       "      <td>stable mild cardiomegaly. no pneumothorax, ple...</td>\n",
       "      <td>stable mild cardiomegaly without acute cardiop...</td>\n",
       "      <td>cardiomegaly_mild,implanted medical device_hum...</td>\n",
       "      <td>CXR1013_IM-0013-1001.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Comparison  Indication  \\\n",
       "13   CXR101             chest pain   \n",
       "14  CXR1011                chronic   \n",
       "15  CXR1013             chest pain   \n",
       "\n",
       "                                             Findings  \\\n",
       "13  the heart is again mildly enlarged. mediastina...   \n",
       "14  the heart is top normal in size. the mediastin...   \n",
       "15  stable mild cardiomegaly. no pneumothorax, ple...   \n",
       "\n",
       "                                           Impression  \\\n",
       "13  1. mild stable cardiomegaly and central vascul...   \n",
       "14                                   no acute disease   \n",
       "15  stable mild cardiomegaly without acute cardiop...   \n",
       "\n",
       "                                                 Mesh  \\\n",
       "13  cardiomegaly_mild,technical quality of image u...   \n",
       "14                                             normal   \n",
       "15  cardiomegaly_mild,implanted medical device_hum...   \n",
       "\n",
       "                       Image  View     Sex  \n",
       "13   CXR101_IM-0011-4004.png   0.0          \n",
       "14  CXR1011_IM-0013-1001.png   0.0          \n",
       "15  CXR1013_IM-0013-1001.png   0.0  female  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(16).tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Indication_Sex'] = df['Indication'] +' '+ df['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3259 entries, 0 to 3258\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ID              3259 non-null   object \n",
      " 1   Comparison      3259 non-null   object \n",
      " 2   Indication      3259 non-null   object \n",
      " 3   Findings        3259 non-null   object \n",
      " 4   Impression      3259 non-null   object \n",
      " 5   Mesh            3259 non-null   object \n",
      " 6   Image           3259 non-null   object \n",
      " 7   View            3259 non-null   float64\n",
      " 8   Sex             3259 non-null   object \n",
      " 9   Indication_Sex  3259 non-null   object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 254.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_features.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_sent = list()\n",
    "findings_word = list()\n",
    "indication_sent = list()\n",
    "indication_word = list()\n",
    "comparison_sent = list()\n",
    "comparison_word = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Comparison', 'Indication', 'Findings', 'Impression', 'Mesh',\n",
       "       'Image', 'View', 'Sex', 'Indication_Sex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = list()\n",
    "image_id = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_word_tokenize(df,col,wordcount):\n",
    "    sent = list()\n",
    "    words = list()\n",
    "    temp = list()\n",
    "    \n",
    "\n",
    "    for row in range(0,df.shape[0]):\n",
    "        \n",
    "        temp = list(map(str.strip, s_tokenizer.tokenize(df[col].iloc[row])))\n",
    "        temp = ' '.join(temp[0].split()[:wordcount])   ### taking first 75 words\n",
    "        temp = ['<start> ' + temp + ' <end>']# for temp in temp]\n",
    "        sent.append(temp)\n",
    "\n",
    "        temp = list(map(str.strip, w_tokenizer.tokenize(df[col].iloc[row])))\n",
    "        words.append(temp)\n",
    "        \n",
    "    return sent,words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(df):\n",
    "    image_name = list()\n",
    "    image_id = list()\n",
    "    for row in range(0,df.shape[0]):\n",
    "        ## Image names & ID\n",
    "        image_name.append(df.Image.iloc[row])\n",
    "        image_id.append(df.ID.iloc[row])\n",
    "    return image_name,image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_sent,findings_word = sent_word_tokenize(df,'Findings',75)\n",
    "indication_sent,indication_word = sent_word_tokenize(df,'Indication_Sex',75)\n",
    "comparison_sent,comparison_word = sent_word_tokenize(df,'Comparison',75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names,image_id = getImage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CXR1013_IM-0013-1001.png'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CXR1013'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_id[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> chest pain female <end>']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indication_sent[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chest', 'pain', 'female']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indication_word[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>  <end>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_sent[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_word[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> stable mild cardiomegaly. no pneumothorax, pleural effusion, or focal airspace disease. bony structures intact. right humeral head bone anchor <end>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findings_sent[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stable',\n",
       " 'mild',\n",
       " 'cardiomegaly',\n",
       " '.',\n",
       " 'no',\n",
       " 'pneumothorax',\n",
       " ',',\n",
       " 'pleural',\n",
       " 'effusion',\n",
       " ',',\n",
       " 'or',\n",
       " 'focal',\n",
       " 'airspace',\n",
       " 'disease',\n",
       " '.',\n",
       " 'bony',\n",
       " 'structures',\n",
       " 'intact',\n",
       " '.',\n",
       " 'right',\n",
       " 'humeral',\n",
       " 'head',\n",
       " 'bone',\n",
       " 'anchor']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findings_word[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determining the average length of words\n",
    "def avglen(input):\n",
    "    lengths = [len(i) for i in input]\n",
    "    sum = 0; j = 0\n",
    "    for i in range(0,len(lengths)):\n",
    "        if lengths[i] > 0:\n",
    "            sum += lengths[i]\n",
    "            j+=1\n",
    "\n",
    "    return (round(sum/j))\n",
    "\n",
    "## Determining the maximum length of words\n",
    "def maxlen(input):\n",
    "    lengths = [len(i) for i in input]\n",
    "    sum = 0; j = 0; max = 5\n",
    "    for i in range(0,len(lengths)):\n",
    "        if lengths[i] > max:\n",
    "            max = lengths[i]\n",
    "            sum+=1\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of Finding word    : 1\n",
      "Max length of Finding word        : 185\n",
      "Average length of Indication : 4\n",
      "Max length of Indication word        : 41\n",
      "Average length of Comparison : 4\n",
      "Max length of Comparison word        : 52\n"
     ]
    }
   ],
   "source": [
    "print (\"Average length of Finding word    : \"+str(avglen(findings_sent)))\n",
    "print (\"Max length of Finding word        : \"+str(maxlen(findings_word)))\n",
    "print (\"Average length of Indication : \"+str(avglen(indication_word)))\n",
    "print (\"Max length of Indication word        : \"+str(maxlen(indication_word)))\n",
    "print (\"Average length of Comparison : \"+str(avglen(comparison_word)))\n",
    "print (\"Max length of Comparison word        : \"+str(maxlen(comparison_word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining constants for maximum length\n",
    "MAX_SENT_LENGTH = 75\n",
    "MAX_SENT = 1\n",
    "MAX_WORDS_INDICATION = 5\n",
    "MAX_WORDS_COMPARISON = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 tokenizers - One for Findings vocabulary & other for Indication/Comparison vocabulary\n",
    "tk_find = Tokenizer(oov_token=\"<unk>\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tk_indcomp = Tokenizer(oov_token=\"<unk>\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> the cardiac silhouette and mediastinum size are within normal limits. there is no pulmonary edema. there is no focal consolidation. there are no of a pleural effusion. there is no evidence of pneumothorax <end>', '<start> the cardiomediastinal silhouette is within normal limits for size and contour. the lungs are normally inflated without evidence of focal airspace disease, pleural effusion, or pneumothorax. stable calcified granuloma within the right upper lung. no acute bone abnormality <end>']\n",
      "['positive tb test', 'chest pain male']\n",
      "['', 'chest radiograph']\n"
     ]
    }
   ],
   "source": [
    "## Word collection\n",
    "findings_texts = [' '.join(x) for x in findings_sent]\n",
    "indication_texts = [' '.join(x) for x in indication_word]\n",
    "comparison_texts = [' '.join(x) for x in comparison_word]\n",
    "\n",
    "print(findings_texts[:2])\n",
    "print(indication_texts[:2])\n",
    "print(comparison_texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two tokenizers - one for findings & other for indication/comparison\n",
    "tk_find.fit_on_texts(findings_texts)\n",
    "tk_find.word_index['<pad>'] = 0\n",
    "\n",
    "tk_indcomp.fit_on_texts(indication_texts+comparison_texts)\n",
    "tk_indcomp.word_index['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n",
      "chest\n",
      "pain\n",
      "of\n",
      "breath\n",
      "radiograph\n",
      "female\n",
      "male\n",
      "and\n",
      "shortness\n",
      "for\n",
      "history\n",
      "view\n",
      "two\n",
      "dyspnea\n",
      "the\n",
      "preop\n",
      "a\n",
      "left\n",
      "right\n",
      "cancer\n",
      "evaluation\n",
      "is\n",
      "patient\n",
      "surgery\n",
      "ct\n",
      "no\n",
      "on\n",
      "x\n",
      "to\n",
      "2\n",
      "status\n",
      "transplant\n",
      "in\n",
      "ppd\n",
      "comparison\n",
      "positive\n",
      "preoperative\n",
      "hypertension\n",
      "pneumonia\n",
      "copd\n",
      "post\n",
      "weeks\n",
      "back\n",
      "lung\n",
      "asthma\n",
      "dated\n",
      "syncope\n",
      "productive\n",
      "one\n",
      "786\n",
      "chronic\n",
      "out\n",
      "from\n",
      "evaluate\n",
      "rib\n",
      "days\n",
      "abdominal\n",
      "portable\n",
      "loss\n",
      "pt\n",
      "rule\n",
      "3\n",
      "vomiting\n",
      "disease\n",
      "wheezing\n",
      "ago\n",
      "tb\n",
      "knee\n",
      "weakness\n",
      "bone\n",
      "sob\n",
      "pre\n",
      "sidedchest\n",
      "smoking\n",
      "hx\n",
      "arm\n",
      "shoulder\n",
      "followup\n",
      "dizziness\n",
      "tuberculosis\n",
      "marrow\n",
      "o\n",
      "heart\n",
      "hypoxia\n",
      "hemoptysis\n",
      "lower\n",
      "1\n",
      "congestion\n",
      "this\n",
      "months\n",
      "breast\n",
      "after\n",
      "bronchitis\n",
      "complaints\n",
      "placement\n",
      "op\n",
      "anddyspnea\n",
      "recent\n",
      "sided\n",
      "mental\n",
      "upper\n",
      "at\n",
      "hip\n",
      "abdomen\n",
      "throat\n",
      "examination\n",
      "renal\n",
      "kidney\n",
      "'s\n",
      "use\n",
      "carcinoma\n",
      "onset\n",
      "andchest\n",
      "tobacco\n",
      "ap\n",
      "vehicle\n",
      "6\n",
      "symptoms\n",
      "exam\n",
      "possible\n",
      "metastatic\n",
      "pneumothorax\n",
      "prostate\n",
      "altered\n",
      "lateral\n",
      "mass\n",
      "nonsmoker\n",
      "x1\n",
      "edema\n",
      "mva\n",
      "pulmonary\n",
      "acute\n",
      "repair\n",
      "today\n",
      "testicular\n",
      "sarcoidosis\n",
      "prior\n",
      "bariatric\n",
      "cp\n",
      "replacement\n",
      "nausea\n",
      "with\n",
      "ofchest\n",
      "has\n",
      "headache\n",
      "exertion\n",
      "numbness\n",
      "pa\n",
      "cxr\n",
      "presents\n",
      "are\n",
      "years\n",
      "r\n",
      "persistent\n",
      "workup\n",
      "neck\n",
      "or\n",
      "x2\n",
      "states\n",
      "shielded\n",
      "scan\n",
      "u\n",
      "ofdyspnea\n",
      "infection\n",
      "bilateral\n",
      "pressure\n",
      "known\n",
      "effusion\n",
      "blood\n",
      "previous\n",
      "5\n",
      "w\n",
      "hernia\n",
      "pleural\n",
      "leg\n",
      "contrast\n",
      "month\n",
      "exacerbation\n",
      "chills\n",
      "mvc\n",
      "chf\n",
      "injury\n",
      "assault\n",
      "low\n",
      "melanoma\n",
      "nodule\n",
      "spine\n",
      "bladder\n",
      "seizure\n",
      "10\n",
      "side\n",
      "ca\n",
      "indication\n",
      "fatigue\n",
      "leftchest\n",
      "sounds\n",
      "total\n",
      "last\n",
      "fracture\n",
      "4\n",
      "up\n",
      "cell\n",
      "h\n",
      "m\n",
      "pelvis\n",
      "test\n",
      "arthritis\n",
      "failure\n",
      "that\n",
      "was\n",
      "c\n",
      "esophageal\n",
      "palpitations\n",
      "9\n",
      "radiographs\n",
      "tightness\n",
      "multiple\n",
      "bmt\n",
      "removal\n",
      "physical\n",
      "quadrant\n",
      "p\n",
      "available\n",
      "single\n",
      "radiating\n",
      "x3\n",
      "oxygen\n",
      "tachycardia\n",
      "starting\n",
      "since\n",
      "lab\n",
      "lymphoma\n",
      "tube\n",
      "now\n",
      "screening\n",
      "sputum\n",
      "anesthesia\n",
      "abnormal\n",
      "cardiac\n",
      "thyroid\n",
      "sore\n",
      "clinical\n",
      "anterior\n",
      "abuse\n",
      "please\n",
      "elevated\n",
      "non\n",
      "episode\n",
      "thoracic\n",
      "crackles\n",
      "increased\n",
      "infiltrate\n",
      "emphysema\n",
      "myeloma\n",
      "hours\n",
      "worsening\n",
      "over\n",
      "bleed\n",
      "hiv\n",
      "pregnant\n",
      "not\n",
      "tumor\n",
      "collision\n",
      "complaining\n",
      "outside\n",
      "syndrome\n",
      "nonproductive\n",
      "accident\n",
      "skin\n",
      "decreased\n",
      "diarrhea\n",
      "both\n",
      "views\n",
      "thorax\n",
      "comparisons\n",
      "scheduled\n",
      "ribs\n",
      "syncopal\n",
      "yesterday\n",
      "lobe\n",
      "anteriorchest\n",
      "unable\n",
      "wound\n",
      "tingling\n",
      "medical\n",
      "increasing\n",
      "body\n",
      "sweats\n",
      "s\n",
      "paindyspnea\n",
      "line\n",
      "f\n",
      "old\n",
      "high\n",
      "artery\n",
      "lungs\n",
      "etoh\n",
      "11\n",
      "05\n",
      "treatment\n",
      "an\n",
      "fibrosis\n",
      "worse\n",
      "feet\n",
      "under\n",
      "cervical\n",
      "7\n",
      "metastasis\n",
      "bypass\n",
      "testis\n",
      "facility\n",
      "hodgkin\n",
      "few\n",
      "lymphadenopathy\n",
      "routine\n",
      "stent\n",
      "stenosis\n",
      "changes\n",
      "head\n",
      "rt\n",
      "rales\n",
      "atrial\n",
      "ovarian\n",
      "wall\n",
      "colon\n",
      "liver\n",
      "she\n",
      "picc\n",
      "mediastinum\n",
      "lightheadedness\n",
      "by\n",
      "sarcoma\n",
      "aortic\n",
      "bleeding\n",
      "coughing\n",
      "mid\n",
      "valve\n",
      "end\n",
      "stage\n",
      "leukocytosis\n",
      "change\n",
      "extremity\n",
      "who\n",
      "reported\n",
      "8\n",
      "50\n",
      "currently\n",
      "486\n",
      "12\n",
      "year\n",
      "cystic\n",
      "started\n",
      "posterior\n",
      "cabg\n",
      "confusion\n",
      "21\n",
      "hour\n",
      "preprocedure\n",
      "diabetes\n",
      "having\n",
      "yrs\n",
      "studies\n",
      "surgical\n",
      "malignant\n",
      "brain\n",
      "abscess\n",
      "cigarette\n",
      "flank\n",
      "osteoarthritis\n",
      "prolapse\n",
      "reaction\n",
      "epigastric\n",
      "catheter\n",
      "hand\n",
      "ankle\n",
      "0\n",
      "30\n",
      "midchest\n",
      "pleuriticchest\n",
      "removed\n",
      "allergic\n",
      "exposure\n",
      "obesity\n",
      "724\n",
      "sensation\n",
      "breathing\n",
      "htn\n",
      "question\n",
      "icd\n",
      "intermittent\n",
      "aspiration\n",
      "sternum\n",
      "onsetdyspnea\n",
      "all\n",
      "been\n",
      "ladder\n",
      "seen\n",
      "alleged\n",
      "aml\n",
      "passed\n",
      "concern\n",
      "tenderness\n",
      "px\n",
      "peripheral\n",
      "anxiety\n",
      "have\n",
      "study\n",
      "films\n",
      "remain\n",
      "clear\n",
      "expanded\n",
      "normal\n",
      "fevers\n",
      "conditions\n",
      "491\n",
      "saturation\n",
      "suspected\n",
      "recurrent\n",
      "asymptomatic\n",
      "midsternalchest\n",
      "correlation\n",
      "deep\n",
      "inspiration\n",
      "frequent\n",
      "versus\n",
      "dx\n",
      "diminished\n",
      "mild\n",
      "prostatectomy\n",
      "feels\n",
      "gunshot\n",
      "heartbeat\n",
      "distress\n",
      "central\n",
      "venous\n",
      "ventral\n",
      "reactive\n",
      "airway\n",
      "inhalation\n",
      "production\n",
      "305\n",
      "malignancy\n",
      "medication\n",
      "beginning\n",
      "irregular\n",
      "face\n",
      "without\n",
      "six\n",
      "scapula\n",
      "fx\n",
      "dysphasia\n",
      "midlinechest\n",
      "also\n",
      "area\n",
      "otherwise\n",
      "closure\n",
      "midback\n",
      "lobectomy\n",
      "pleuritic\n",
      "fibrillation\n",
      "obstruction\n",
      "choking\n",
      "does\n",
      "like\n",
      "arthroplasty\n",
      "lat\n",
      "worseningdyspnea\n",
      "hepatocellular\n",
      "follow\n",
      "leukemia\n",
      "code\n",
      "posteriorchest\n",
      "around\n",
      "postop\n",
      "morbid\n",
      "pregnancy\n",
      "59\n",
      "radiates\n",
      "into\n",
      "falling\n",
      "neoplasm\n",
      "substernalchest\n",
      "nodules\n",
      "grade\n",
      "wheeze\n",
      "t\n",
      "complains\n",
      "sched\n",
      "atelectasis\n",
      "polysubstance\n",
      "dizzy\n",
      "ear\n",
      "coronary\n",
      "performed\n",
      "pancreatic\n",
      "mastectomy\n",
      "rectal\n",
      "bronchiectasis\n",
      "carotid\n",
      "onsetchest\n",
      "long\n",
      "femoral\n",
      "intermittently\n",
      "lightheaded\n",
      "cyst\n",
      "difficulty\n",
      "mitral\n",
      "inguinal\n",
      "rheumatoid\n",
      "flutter\n",
      "nightsweats\n",
      "foot\n",
      "joint\n",
      "xray\n",
      "radiation\n",
      "due\n",
      "occasional\n",
      "sarcoid\n",
      "earlier\n",
      "immigrant\n",
      "active\n",
      "v76\n",
      "more\n",
      "than\n",
      "hemorrhage\n",
      "steps\n",
      "laryngeal\n",
      "tonight\n",
      "admit\n",
      "comments\n",
      "79\n",
      "air\n",
      "osteoporosis\n",
      "'t\n",
      "feel\n",
      "well\n",
      "along\n",
      "several\n",
      "muscle\n",
      "174\n",
      "ekg\n",
      "consolidation\n",
      "allogeneic\n",
      "l\n",
      "palpitation\n",
      "arterial\n",
      "pancreatitis\n",
      "organ\n",
      "anemia\n",
      "40\n",
      "arrest\n",
      "assessment\n",
      "v70\n",
      "wheelchair\n",
      "term\n",
      "hospice\n",
      "initiation\n",
      "medicine\n",
      "lipoma\n",
      "01\n",
      "unwitnessed\n",
      "scapular\n",
      "hemodialysis\n",
      "jaw\n",
      "resection\n",
      "apnea\n",
      "cirrhosis\n",
      "therapy\n",
      "re\n",
      "272\n",
      "719\n",
      "41\n",
      "185\n",
      "contusion\n",
      "pericardial\n",
      "sinus\n",
      "home\n",
      "rightchest\n",
      "level\n",
      "achalasia\n",
      "mediastinal\n",
      "germ\n",
      "osteomyelitis\n",
      "kicked\n",
      "cholecystectomy\n",
      "generalized\n",
      "soreness\n",
      "lt\n",
      "abd\n",
      "mammogram\n",
      "adenopathy\n",
      "distal\n",
      "foreign\n",
      "femur\n",
      "hyperstimulation\n",
      "rest\n",
      "abnormality\n",
      "vertigo\n",
      "clot\n",
      "rll\n",
      "aneurysm\n",
      "postmenopausal\n",
      "compari\n",
      "colostomy\n",
      "prev\n",
      "cll\n",
      "eating\n",
      "calculi\n",
      "assess\n",
      "position\n",
      "rhonchi\n",
      "yr\n",
      "14\n",
      "repeat\n",
      "stab\n",
      "pleurisy\n",
      "congestive\n",
      "diagnosis\n",
      "coarse\n",
      "lumbar\n",
      "hypertensive\n",
      "urgency\n",
      "additional\n",
      "v72\n",
      "02\n",
      "v\n",
      "date\n",
      "lowerchest\n",
      "approx\n",
      "09\n",
      "couple\n",
      "dka\n",
      "goiter\n",
      "thyroidectomy\n",
      "infiltrates\n",
      "recurrence\n",
      "recently\n",
      "diagnosed\n",
      "nasal\n",
      "cheek\n",
      "inside\n",
      "graft\n",
      "open\n",
      "746\n",
      "requirement\n",
      "ecf\n",
      "bloody\n",
      "466\n",
      "aam\n",
      "stabbing\n",
      "drainage\n",
      "blurry\n",
      "vision\n",
      "findings\n",
      "dvt\n",
      "46\n",
      "elbow\n",
      "gland\n",
      "chemotherapy\n",
      "embolism\n",
      "energy\n",
      "postpartum\n",
      "fractures\n",
      "meds\n",
      "assisted\n",
      "living\n",
      "iritis\n",
      "hepatic\n",
      "encephalopathy\n",
      "three\n",
      "unavailable\n",
      "esophagus\n",
      "taking\n",
      "feeling\n",
      "dehydration\n",
      "will\n",
      "be\n",
      "spinal\n",
      "tried\n",
      "presyncope\n",
      "wt\n",
      "additionally\n",
      "other\n",
      "murmur\n",
      "tnf\n",
      "revision\n",
      "obtain\n",
      "dialysis\n",
      "indigestion\n",
      "stents\n",
      "eye\n",
      "tetralogy\n",
      "fallot\n",
      "unresponsive\n",
      "troponin\n",
      "previously\n",
      "thoracentesis\n",
      "myocardial\n",
      "hematemesis\n",
      "sepsis\n",
      "pelvic\n",
      "hemopytosis\n",
      "uveitis\n",
      "gangrene\n",
      "increasingdyspnea\n",
      "hemorrhoidectomy\n",
      "23\n",
      "15\n",
      "time\n",
      "angiography\n",
      "intravenous\n",
      "frontal\n",
      "cta\n",
      "image\n",
      "thoracolumbar\n",
      "present\n",
      "acetabular\n",
      "subjective\n",
      "bangladesh\n",
      "pruritic\n",
      "nonprod\n",
      "cought\n",
      "fibrotic\n",
      "but\n",
      "burmese\n",
      "complete\n",
      "ethanol\n",
      "attack\n",
      "evidence\n",
      "supportive\n",
      "housing\n",
      "sinusitis\n",
      "emesis\n",
      "diaphoresis\n",
      "intracranial\n",
      "enlarged\n",
      "lymph\n",
      "ealier\n",
      "joints\n",
      "mostly\n",
      "20\n",
      "midline\n",
      "slurred\n",
      "speech\n",
      "could\n",
      "bulging\n",
      "fibrosing\n",
      "mediastinitis\n",
      "surveillance\n",
      "uti\n",
      "hematoma\n",
      "flulike\n",
      "tachycardic\n",
      "room\n",
      "98\n",
      "liters\n",
      "afib\n",
      "axilla\n",
      "necrotizing\n",
      "granulomas\n",
      "doesn\n",
      "bcg\n",
      "vaccination\n",
      "ingestion\n",
      "overseas\n",
      "spasms\n",
      "esr\n",
      "92\n",
      "backache\n",
      "ventilation\n",
      "perfusion\n",
      "cck\n",
      "levels\n",
      "melonoma\n",
      "basilar\n",
      "very\n",
      "episodes\n",
      "polyarthralgia\n",
      "allogenic\n",
      "it\n",
      "07\n",
      "66yof\n",
      "desaturation\n",
      "overnight\n",
      "slipped\n",
      "sclerosis\n",
      "endstage\n",
      "internal\n",
      "fixation\n",
      "nondependent\n",
      "subclavian\n",
      "dexa\n",
      "onto\n",
      "780\n",
      "lb\n",
      "hiatal\n",
      "scleroderma\n",
      "drug\n",
      "induced\n",
      "35\n",
      "ordered\n",
      "clavicle\n",
      "excision\n",
      "424\n",
      "414\n",
      "membranoproliferative\n",
      "glomerulonephritis\n",
      "below\n",
      "breasts\n",
      "specified\n",
      "device\n",
      "syphilis\n",
      "wrist\n",
      "completed\n",
      "burshechest\n",
      "elbowed\n",
      "partial\n",
      "tinged\n",
      "duchenne\n",
      "muscular\n",
      "dystrophy\n",
      "hyperglycemia\n",
      "sbp\n",
      "osteopenia\n",
      "ramicade\n",
      "v58\n",
      "69\n",
      "altercation\n",
      "pretibial\n",
      "lesion\n",
      "food\n",
      "'\n",
      "serum\n",
      "humira\n",
      "st\n",
      "transpleural\n",
      "biloma\n",
      "loculated\n",
      "us\n",
      "resulting\n",
      "consciousness\n",
      "walks\n",
      "lbot\n",
      "hepatitis\n",
      "pda\n",
      "axillary\n",
      "section\n",
      "malaise\n",
      "pkd\n",
      "dm\n",
      "xol\n",
      "significant\n",
      "alveolar\n",
      "aches\n",
      "calc\n",
      "tibia\n",
      "pacs\n",
      "labeled\n",
      "sfhhc\n",
      "723\n",
      "swallowed\n",
      "fractured\n",
      "51\n",
      "contact\n",
      "heaviness\n",
      "calf\n",
      "herniated\n",
      "disc\n",
      "vs\n",
      "x9\n",
      "acacerbati\n",
      "takedown\n",
      "bilat\n",
      "effusions\n",
      "chronicdyspnea\n",
      "lumbago\n",
      "cervicalgia\n",
      "acquired\n",
      "rapid\n",
      "skilled\n",
      "t12\n",
      "490\n",
      "unspecified\n",
      "43\n",
      "rolled\n",
      "reversal\n",
      "b\n",
      "menopausal\n",
      "apparent\n",
      "look\n",
      "remember\n",
      "happened\n",
      "cachectic\n",
      "54yof\n",
      "attn\n",
      "direct\n",
      "migraine\n",
      "53yof\n",
      "admitted\n",
      "ureteral\n",
      "nosebleed\n",
      "unrelieved\n",
      "conservative\n",
      "caucasian\n",
      "ptx\n",
      "confused\n",
      "range\n",
      "motion\n",
      "dorv\n",
      "hiccups\n",
      "arrhythmia\n",
      "x6\n",
      "cutaneous\n",
      "circumcision\n",
      "tamoxifen\n",
      "anchest\n",
      "regurgitation\n",
      "employment\n",
      "jm\n",
      "uip\n",
      "persistentdyspnea\n",
      "morbidly\n",
      "obese\n",
      "x4\n",
      "52\n",
      "hypotension\n",
      "atypical\n",
      "commissure\n",
      "14th\n",
      "82\n",
      "gyn\n",
      "799\n",
      "approximately\n",
      "47\n",
      "correlate\n",
      "q\n",
      "pyeloplasty\n",
      "reduction\n",
      "he\n",
      "antibiotics\n",
      "34yof\n",
      "activity\n",
      "100\n",
      "kub\n",
      "constipation\n",
      "diabetic\n",
      "ketoacidosis\n",
      "expiratory\n",
      "outsidechest\n",
      "diffusechest\n",
      "instance\n",
      "temperature\n",
      "increaseddyspnea\n",
      "hyperlidemia\n",
      "pn\n",
      "lipase\n",
      "presenting\n",
      "stepping\n",
      "pnuemonia\n",
      "exsmoker\n",
      "experiencingdyspnea\n",
      "emphysemia\n",
      "lymphoid\n",
      "compressive\n",
      "pneumomediastinum\n",
      "adrenalectomy\n",
      "hypoxic\n",
      "suffered\n",
      "cannula\n",
      "caught\n",
      "nose\n",
      "white\n",
      "hemoglobin\n",
      "sent\n",
      "795\n",
      "involved\n",
      "tumors\n",
      "nodular\n",
      "denisities\n",
      "osh\n",
      "stated\n",
      "pulmonic\n",
      "codes\n",
      "actinomyces\n",
      "healing\n",
      "andshortness\n",
      "prolonged\n",
      "intubation\n",
      "induction\n",
      "30yof\n",
      "soft\n",
      "tissue\n",
      "ventilator\n",
      "myopericarditis\n",
      "esoph\n",
      "lethargy\n",
      "anus\n",
      "inj\n",
      "dehydrated\n",
      "odyspnea\n",
      "dizzyness\n",
      "migranes\n",
      "always\n",
      "endarterectomy\n",
      "iv\n",
      "''s\n",
      "remove\n",
      "gown\n",
      "asbestos\n",
      "followed\n",
      "middle\n",
      "homeless\n",
      "pretransplant\n",
      "seasonal\n",
      "immunosuppre\n",
      "forearm\n",
      "swimmer\n",
      "hypercalcemia\n",
      "53\n",
      "flu\n",
      "bathtub\n",
      "nonradiating\n",
      "histo\n",
      "collapse\n",
      "centralchest\n",
      "hypoxemia\n",
      "bradycardia\n",
      "50chest\n",
      "stomach\n",
      "783\n",
      "yellowish\n",
      "rhinitis\n",
      "synovial\n",
      "bruising\n",
      "occasionalchest\n",
      "721\n",
      "10lb\n",
      "unintentional\n",
      "information\n",
      "obtained\n",
      "electronic\n",
      "record\n",
      "acid\n",
      "reflux\n",
      "metastases\n",
      "dementia\n",
      "retroperitoneal\n",
      "flare\n",
      "abscesses\n",
      "depression\n",
      "dyskinesia\n",
      "cellulitis\n",
      "sdh\n",
      "hypokalemia\n",
      "593\n",
      "parotid\n",
      "pneumonias\n",
      "type\n",
      "increases\n",
      "airbag\n",
      "immunodeficiency\n",
      "inflammatory\n",
      "tract\n",
      "painchest\n",
      "insufficiency\n",
      "focalchest\n",
      "lasts\n",
      "occurs\n",
      "once\n",
      "anorexia\n",
      "neurostimulator\n",
      "wheezes\n",
      "clubbing\n",
      "roomate\n",
      "sts\n",
      "hasn\n",
      "drinking\n",
      "anything\n",
      "t8\n",
      "wks\n",
      "processes\n",
      "xiphoid\n",
      "metastic\n",
      "seizures\n",
      "per\n",
      "sacroiliitis\n",
      "immunosuppressive\n",
      "myotomy\n",
      "retained\n",
      "varices\n",
      "walking\n",
      "oxygenation\n",
      "muscles\n",
      "swallowing\n",
      "leiomyosarcoma\n",
      "thanksgiving\n",
      "mitomyopathy\n",
      "painting\n",
      "weekend\n",
      "neuropathy\n",
      "base\n",
      "deltoid\n",
      "proximal\n",
      "biopsy\n",
      "hyperosmolar\n",
      "state\n",
      "scrotal\n",
      "transfer\n",
      "485\n",
      "persisting\n",
      "tka\n",
      "incontinence\n",
      "tubes\n",
      "lines\n",
      "growing\n",
      "pseudomonas\n",
      "ablation\n",
      "pdp\n",
      "elevation\n",
      "before\n",
      "immunosuppression\n",
      "toothache\n",
      "t4\n",
      "supraglottic\n",
      "squamous\n",
      "temporal\n",
      "barrett\n",
      "antibiotic\n",
      "bases\n",
      "cholecystitis\n",
      "operated\n",
      "rotator\n",
      "401\n",
      "entering\n",
      "svt\n",
      "vocal\n",
      "cord\n",
      "paralysis\n",
      "costochondralchest\n",
      "sbrt\n",
      "hcc\n",
      "involuntary\n",
      "movements\n",
      "59chest\n",
      "cholesterol\n",
      "58\n",
      "lbs\n",
      "downstairs\n",
      "o2\n",
      "coming\n",
      "arthroscopy\n",
      "716\n",
      "81\n",
      "arthropathy\n",
      "v74\n",
      "585\n",
      "insuffcieny\n",
      "ambulance\n",
      "forchest\n",
      "colorectal\n",
      "impression\n",
      "using\n",
      "crutches\n",
      "broken\n",
      "continued\n",
      "exacerbations\n",
      "ruq\n",
      "nephrectomy\n",
      "eight\n",
      "inactive\n",
      "v12\n",
      "receiving\n",
      "tubal\n",
      "dyspneachest\n",
      "hyperviscosity\n",
      "39\n",
      "streaked\n",
      "further\n",
      "ordering\n",
      "physician\n",
      "anteriorly\n",
      "fwc\n",
      "sx\n",
      "nipple\n",
      "markers\n",
      "tof\n",
      "methotrexate\n",
      "embolus\n",
      "cardioversion\n",
      "bodyaches\n",
      "shaking\n",
      "stones\n",
      "exertionaldyspnea\n",
      "reads\n",
      "bacterial\n",
      "dis\n",
      "behind\n",
      "mri\n",
      "improvement\n",
      "implant\n",
      "carcinoid\n",
      "about\n",
      "somechest\n",
      "tonsillar\n",
      "midaxillary\n",
      "half\n",
      "histoplasmosis\n",
      "vascular\n",
      "appendix\n",
      "throughout\n",
      "care\n",
      "false\n",
      "rhinoplasty\n",
      "reevaluate\n",
      "headaches\n",
      "60\n",
      "hoarseness\n",
      "hyperlipidemia\n",
      "idiopathic\n",
      "decompression\n",
      "remote\n",
      "pos\n",
      "pedestrian\n",
      "causes\n",
      "implants\n",
      "54\n",
      "outlet\n",
      "ventricle\n",
      "transposition\n",
      "great\n",
      "infarction\n",
      "requirements\n",
      "small\n",
      "bowel\n",
      "choroidal\n",
      "lesions\n",
      "dissection\n",
      "enbrel\n",
      "pod\n",
      "vhr\n",
      "occasionaldyspnea\n",
      "five\n",
      "unspecchest\n",
      "infections\n",
      "polyarticular\n",
      "shower\n",
      "inr\n",
      "nosebleeds\n",
      "osteogenic\n",
      "sfwp\n",
      "attacks\n",
      "30p\n",
      "kg\n",
      "pancreas\n",
      "vaginal\n",
      "vault\n",
      "pushed\n",
      "strep\n",
      "viridans\n",
      "bacteremia\n",
      "neutropenia\n",
      "strangulated\n",
      "cig\n",
      "ischemia\n",
      "cva\n",
      "tripped\n",
      "letting\n",
      "raise\n",
      "function\n",
      "infarct\n",
      "fordyspnea\n",
      "hep\n",
      "v42\n",
      "replaced\n",
      "transp\n",
      "pilonidal\n",
      "progressive\n",
      "despite\n",
      "adrenal\n",
      "hysterectomy\n",
      "cocaine\n",
      "inability\n",
      "y\n",
      "moving\n",
      "endometrial\n",
      "severe\n",
      "hf\n",
      "exertionalchest\n",
      "chemical\n",
      "collection\n",
      "attempting\n",
      "pills\n",
      "overdose\n",
      "catheterization\n",
      "preadmission\n",
      "asymmetric\n",
      "radial\n",
      "pulses\n",
      "thrombosis\n",
      "x7\n",
      "positvie\n",
      "language\n",
      "get\n",
      "cardiomyopathy\n",
      "cramping\n",
      "31yof\n",
      "football\n",
      "found\n",
      "injuries\n",
      "lp\n",
      "aids\n",
      "vsd\n",
      "ampullary\n",
      "adenocarcinoma\n",
      "crisis\n",
      "lumpectomy\n",
      "stool\n",
      "84\n",
      "218\n",
      "60y\n",
      "sp\n",
      "009\n",
      "immigration\n",
      "glenohumeral\n",
      "show\n",
      "slight\n",
      "narrowing\n",
      "less\n",
      "distinct\n",
      "alignment\n",
      "common\n",
      "resolution\n",
      "were\n",
      "dictation\n",
      "if\n",
      "become\n",
      "addendum\n",
      "56\n",
      "73\n",
      "same\n",
      "cd\n",
      "identified\n",
      "name\n",
      "24\n",
      "tips\n",
      "127\n",
      "film\n",
      "there\n",
      "gynoid\n",
      "19\n",
      "report\n",
      "only\n",
      "dextroscoliosis\n",
      "size\n",
      "suture\n",
      "radiographically\n",
      "26\n",
      "22\n",
      "007\n",
      "redressed\n",
      "17\n",
      "institution\n",
      "hch\n",
      "levoscoliosis\n",
      "urogram\n",
      "ultrasound\n",
      "guided\n",
      "adaptation\n",
      "plates\n",
      "almost\n",
      "completely\n",
      "obliterated\n",
      "large\n",
      "osteophytes\n",
      "08\n",
      "rehabilitation\n",
      "part\n",
      "cbd\n",
      "743\n",
      "which\n",
      "included\n",
      "runoff\n",
      "respectively\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "for item in tk_indcomp.word_index:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n"
     ]
    }
   ],
   "source": [
    "for item in tk_indcomp.index_word:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'respectively'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_indcomp.index_word[1384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of findings word index              : 1500\n",
      "Length of indication/comparison word index : 1385\n"
     ]
    }
   ],
   "source": [
    "## Total words using the word list from all features & labels\n",
    "print (\"Length of findings word index              : \"+str(len(tk_find.word_index)))\n",
    "print (\"Length of indication/comparison word index : \"+str(len(tk_indcomp.word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorizing Findings\n",
    "findings_seq = [tk_find.texts_to_sequences(x) for x in findings_sent]\n",
    "\n",
    "# Aligning with the max sentences \n",
    "for x in findings_seq:\n",
    "    while len(x) < MAX_SENT:\n",
    "        x.append([0])\n",
    "        \n",
    "    if len(x) > MAX_SENT:\n",
    "        del x[MAX_SENT:]\n",
    "\n",
    "# Padding sequences for uniform sentence word length\n",
    "findings_vector = [pad_sequences(x, padding='post', maxlen=MAX_SENT_LENGTH) for x in findings_seq]\n",
    "\n",
    "## Changing the first word as \"<start>\" for findings with more than 75 words\n",
    "for i in range(0, len(findings_vector)):\n",
    "    if findings_vector[i][0][74] == 8 :\n",
    "        findings_vector[i][0][0] = 7   ## \"7\" is the vector value for <start>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> both lungs are clear and expanded with no infiltrates. basilar focal atelectasis is present in the lingula. heart size normal. calcified right hilar are present <end>']\n",
      "[[6, 100, 17, 4, 20, 9, 105, 36, 3, 118, 174, 19, 78, 5, 77, 23, 2, 340, 16, 18, 8, 53, 27, 99, 4, 77, 7]]\n",
      "[[  6 100  17   4  20   9 105  36   3 118 174  19  78   5  77  23   2 340\n",
      "   16  18   8  53  27  99   4  77   7   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "n=20\n",
    "print(findings_sent[n])\n",
    "print(findings_seq[n])\n",
    "print(findings_vector[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorizing Comparison\n",
    "comparison_seq = [tk_indcomp.texts_to_sequences(x) for x in comparison_sent]\n",
    "\n",
    "## Taking only one sentence \n",
    "for x in comparison_seq:\n",
    "    while len(x) < 1:\n",
    "        x.append([0])\n",
    "        \n",
    "    if len(x) > 1:\n",
    "        del x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>  <end>']\n",
      "[[1 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Padding sequences for uniform sentence word length\n",
    "comparison_vector = [pad_sequences(x, padding='post', maxlen=MAX_WORDS_COMPARISON) for x in comparison_seq]\n",
    "print(comparison_sent[205])\n",
    "print(comparison_vector[205])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorizing Indication\n",
    "indication_seq = [tk_indcomp.texts_to_sequences(x) for x in indication_sent]\n",
    "\n",
    "## Taking only one sentence \n",
    "for x in indication_seq:\n",
    "    while len(x) < 1:\n",
    "        x.append([0])\n",
    "        \n",
    "    if len(x) > 1:\n",
    "        del x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> shortness of breath of breath male <end>']\n",
      "[[5 4 5 8 1]]\n"
     ]
    }
   ],
   "source": [
    "# Padding sequences for uniform sentence word length\n",
    "indication_vector = [pad_sequences(x, padding='post', maxlen=MAX_WORDS_INDICATION) for x in indication_seq]\n",
    "print(indication_sent[45])\n",
    "print(indication_vector[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Vectorization Using Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = 'G:\\\\acra\\\\imagesource\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedf = pd.DataFrame(columns = ['Image'],data = df.Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1_1_IM-0001-4001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR10_IM-0002-1001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR10_IM-0002-2001.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Image\n",
       "0  CXR1_1_IM-0001-4001.png\n",
       "1   CXR10_IM-0002-1001.png\n",
       "2   CXR10_IM-0002-2001.png"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagedf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = []\n",
    "\n",
    "for i in range(0,imagedf.shape[0]):\n",
    "    img = cv2.imread(imgpath+df[\"Image\"][i].upper())\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   \n",
    "    img = cv2.resize(img,(299,299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    image_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.56078434, -0.56078434, -0.56078434],\n",
       "         [-0.6392157 , -0.6392157 , -0.6392157 ],\n",
       "         [-0.6392157 , -0.6392157 , -0.6392157 ],\n",
       "         ...,\n",
       "         [-0.75686276, -0.75686276, -0.75686276],\n",
       "         [-0.6862745 , -0.6862745 , -0.6862745 ],\n",
       "         [-0.60784316, -0.60784316, -0.60784316]],\n",
       "\n",
       "        [[-0.654902  , -0.654902  , -0.654902  ],\n",
       "         [-0.67058825, -0.67058825, -0.67058825],\n",
       "         [-0.6862745 , -0.6862745 , -0.6862745 ],\n",
       "         ...,\n",
       "         [-0.77254903, -0.77254903, -0.77254903],\n",
       "         [-0.7176471 , -0.7176471 , -0.7176471 ],\n",
       "         [-0.6392157 , -0.6392157 , -0.6392157 ]],\n",
       "\n",
       "        [[-0.6627451 , -0.6627451 , -0.6627451 ],\n",
       "         [-0.67058825, -0.67058825, -0.67058825],\n",
       "         [-0.6862745 , -0.6862745 , -0.6862745 ],\n",
       "         ...,\n",
       "         [-0.78039217, -0.78039217, -0.78039217],\n",
       "         [-0.7254902 , -0.7254902 , -0.7254902 ],\n",
       "         [-0.6392157 , -0.6392157 , -0.6392157 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.67058825, -0.67058825, -0.67058825],\n",
       "         [-0.6862745 , -0.6862745 , -0.6862745 ],\n",
       "         [-0.6784314 , -0.6784314 , -0.6784314 ],\n",
       "         ...,\n",
       "         [-0.8039216 , -0.8039216 , -0.8039216 ],\n",
       "         [-0.77254903, -0.77254903, -0.77254903],\n",
       "         [-0.7254902 , -0.7254902 , -0.7254902 ]],\n",
       "\n",
       "        [[-0.6627451 , -0.6627451 , -0.6627451 ],\n",
       "         [-0.67058825, -0.67058825, -0.67058825],\n",
       "         [-0.67058825, -0.67058825, -0.67058825],\n",
       "         ...,\n",
       "         [-0.79607844, -0.79607844, -0.79607844],\n",
       "         [-0.77254903, -0.77254903, -0.77254903],\n",
       "         [-0.7254902 , -0.7254902 , -0.7254902 ]],\n",
       "\n",
       "        [[-0.5137255 , -0.5137255 , -0.5137255 ],\n",
       "         [-0.5294118 , -0.5294118 , -0.5294118 ],\n",
       "         [-0.5294118 , -0.5294118 , -0.5294118 ],\n",
       "         ...,\n",
       "         [-0.7647059 , -0.7647059 , -0.7647059 ],\n",
       "         [-0.7411765 , -0.7411765 , -0.7411765 ],\n",
       "         [-0.70980394, -0.70980394, -0.70980394]]]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_inception_model():\n",
    "    # Initialize InceptionV3 and load the pretrained Imagenet weights\n",
    "    model = InceptionV3(include_top=False,  weights='imagenet', input_shape=(299,299,3))\n",
    "    new_input = model.input\n",
    "    hidden_layer = model.layers[-1].output\n",
    "\n",
    "    return Model(new_input, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_inception_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image_features = list()\n",
    "for i in range(0,len(image_train)):\n",
    "    image_features.append(model.predict(image_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 8, 2048)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image vector dimensionality reduction\n",
    "def model_dim_reduction():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(2048,(1,1), input_shape=(8, 8, 2048), activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(1024,(1,1), activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(512,(1,1), activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_red = model_dim_reduction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_94 (Conv2D)           (None, 8, 8, 2048)        4196352   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 4, 4, 1024)        2098176   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_10 (Averag (None, 2, 2, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 2, 2, 512)         524800    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_11 (Averag (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 6,819,328\n",
      "Trainable params: 6,819,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_red.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Feature extraction - 512 features from original image\n",
    "image_features_final = []\n",
    "for i in range(0,len(image_features)):\n",
    "    image_features_final.append(model_red.predict(image_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of each image   : (1, 512)\n",
      "Number of images      : 3259\n",
      "Number of Indications : 3259\n",
      "Number of Comparison  : 3259\n",
      "Number of Findings    : 3259\n",
      "Vocab size of find       : 1500\n",
      "Vocab size of indcomp    : 1385\n"
     ]
    }
   ],
   "source": [
    "## Features and labels shape\n",
    "print (\"Shape of each image   : \"+str(image_features_final[0].shape))\n",
    "print (\"Number of images      : \"+str(len(image_features_final)))\n",
    "print (\"Number of Indications : \"+str(len(indication_vector)))\n",
    "print (\"Number of Comparison  : \"+str(len(comparison_vector)))\n",
    "print (\"Number of Findings    : \"+str(len(findings_vector)))\n",
    "\n",
    "vocab_size_find = len(tk_find.word_index)\n",
    "vocab_size_indcomp = len(tk_indcomp.word_index)\n",
    "print (\"Vocab size of find       : \"+str(vocab_size_find))\n",
    "print (\"Vocab size of indcomp    : \"+str(vocab_size_indcomp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Sequence For Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(tokenizer, max_length, images, comparison, indication, findings, vocab_size):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    X3 = []\n",
    "    X4 = []\n",
    "    y = []\n",
    "    # walk through each image identifier\n",
    "    for a in range(0,len(images)):\n",
    "        for i in range(0, len(findings[a])):\n",
    "            # walk through each description for the image\n",
    "            # encode the sequence\n",
    "            seq = findings[a][i]\n",
    "            # split one sequence into multiple X,y pairs\n",
    "            for j in range(1, len(seq)):\n",
    "                # split into input and output pair\n",
    "                in_seq, out_seq = seq[:j], seq[j]\n",
    "                # pad input sequence\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                # encode output sequence\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                if (len(images) == 1):\n",
    "                    X1.append(images[a])\n",
    "                    X2.append(comparison[a])\n",
    "                    X3.append(indication[a])\n",
    "                    X4.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "                else:\n",
    "                    X1.append(images[a][0])\n",
    "                    X2.append(comparison[a][0])\n",
    "                    X3.append(indication[a][0])\n",
    "                    X4.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "    return X1, X2, X3, X4, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_image, X2_comp, X3_ind, X4_find, Y_find = create_sequences(tk_find, MAX_SENT_LENGTH, image_features_final, comparison_vector, \n",
    "                                                            indication_vector, findings_vector, vocab_size_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of each image   : (512,)\n",
      "Number of images      : 241166\n",
      "\n",
      "Shape of Comparison   : (7,)\n",
      "Number of Comparison    : 241166\n",
      "\n",
      "Shape of Indication   : (5,)\n",
      "Number of Indication    : 241166\n",
      "\n",
      "Shape of Findings     : (75,)\n",
      "Number of Findings      : 241166\n",
      "\n",
      "Shape of Output sequence     : (1500,)\n",
      "Number of Output sequences     : 241166\n"
     ]
    }
   ],
   "source": [
    "## Shape of sequences\n",
    "print (\"Shape of each image   : \"+str(X1_image[0].shape))\n",
    "print (\"Number of images      : \"+str(len(X1_image)))\n",
    "\n",
    "print (\"\\nShape of Comparison   : \"+str(X2_comp[0].shape))\n",
    "print (\"Number of Comparison    : \"+str(len(X2_comp)))\n",
    "\n",
    "print (\"\\nShape of Indication   : \"+str(X3_ind[0].shape))\n",
    "print (\"Number of Indication    : \"+str(len(X3_ind)))\n",
    "\n",
    "print (\"\\nShape of Findings     : \"+str(X4_find[0].shape))\n",
    "print (\"Number of Findings      : \"+str(len(X4_find)))\n",
    "\n",
    "print (\"\\nShape of Output sequence     : \"+str(Y_find[0].shape))\n",
    "print (\"Number of Output sequences     : \"+str(len(Y_find)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding using Radglove (Radiology Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 112343 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('radglove.800M.100d.txt',encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 100)\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_find = np.zeros((vocab_size_find, 100))\n",
    "\n",
    "for word, i in tk_find.word_index.items():\n",
    "    embedding_vector_find = embeddings_index.get(word)\n",
    "    if embedding_vector_find is not None:\n",
    "        embedding_matrix_find[i] = embedding_vector_find\n",
    "        \n",
    "print (embedding_matrix_find.shape)\n",
    "print (len(tk_find.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_find[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "<end>\n",
      "cannot\n",
      "patient's\n",
      "there's\n",
      "verterbroplasty\n",
      "these't\n",
      "angulate\n",
      "epipericardial\n",
      "they're\n",
      "today's\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "## Words not present in RADGLOVE\n",
    "tot = 0\n",
    "list = []\n",
    "for i in range(0,len(embedding_matrix_find)):\n",
    "    if ((embedding_matrix_find[i].all()==0)):\n",
    "        tot+=1\n",
    "        list.append(i)\n",
    "\n",
    "for key, value in tk_find.word_index.items() :\n",
    "    if value in list:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indication / Comparison Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1385, 100)\n",
      "1385\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_indcomp = np.zeros((vocab_size_indcomp, 100))\n",
    "\n",
    "for word, i in tk_indcomp.word_index.items():\n",
    "    embedding_vector_indcomp = embeddings_index.get(word)\n",
    "    if embedding_vector_indcomp is not None:\n",
    "        embedding_matrix_indcomp[i] = embedding_vector_indcomp\n",
    "        \n",
    "print (embedding_matrix_indcomp.shape)\n",
    "print (len(tk_indcomp.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.77629995e-01, -8.00965011e-01, -8.54147017e-01, -5.62286973e-01,\n",
       "       -7.39606977e-01, -3.95869985e-02, -2.31326997e-01,  6.34199977e-01,\n",
       "       -3.47305000e-01,  7.44826972e-01, -3.31815988e-01, -4.60662991e-01,\n",
       "       -9.02850032e-02,  5.07996976e-01, -1.10686398e+00,  5.44201016e-01,\n",
       "        1.44619003e-01,  2.17151999e-01, -4.57653999e-01,  1.34213999e-01,\n",
       "       -4.69660014e-02, -8.33532989e-01,  3.72435987e-01, -1.21990005e-02,\n",
       "        3.79870012e-02,  7.93370008e-02,  1.12489402e+00,  3.60424995e-01,\n",
       "       -5.74705005e-01,  9.26158011e-01, -2.92780008e-02,  5.32015026e-01,\n",
       "       -5.08249998e-02, -7.55836010e-01,  4.97471988e-01,  7.98189998e-01,\n",
       "       -9.52907979e-01, -1.30969405e+00,  2.94681996e-01,  4.00492996e-01,\n",
       "        2.30508998e-01, -4.85868990e-01, -1.26350999e-01,  4.17813003e-01,\n",
       "        4.80235994e-01, -4.50929999e-02, -2.74278015e-01,  1.45706996e-01,\n",
       "       -5.00367999e-01, -2.21178994e-01,  1.45514995e-01,  8.86384010e-01,\n",
       "       -2.65899999e-03,  1.01677999e-01, -8.58525991e-01, -4.16931987e-01,\n",
       "        2.07127005e-01,  4.22302991e-01, -5.78979015e-01,  1.30040005e-01,\n",
       "       -6.18152976e-01,  1.39257997e-01,  4.51494008e-01, -1.47245300e+00,\n",
       "        7.73651004e-01, -2.78380990e-01, -2.47064993e-01, -1.83302000e-01,\n",
       "       -7.50361979e-01, -1.48568004e-01, -1.77590996e-01,  2.14999993e-04,\n",
       "        2.19661996e-01, -2.51574010e-01,  3.62066001e-01, -4.99237001e-01,\n",
       "       -1.43683001e-01,  6.35191023e-01, -2.03207999e-01,  4.18357015e-01,\n",
       "       -9.60490033e-02, -2.01697007e-01,  5.89352012e-01, -1.15042999e-01,\n",
       "       -6.80918992e-01,  2.60049999e-01, -3.89324993e-01, -8.72170031e-02,\n",
       "        6.15780018e-02, -2.96124011e-01, -2.63184994e-01,  5.05953014e-01,\n",
       "       -6.55677974e-01,  3.49590003e-01, -5.22990003e-02, -2.34064996e-01,\n",
       "       -5.39583027e-01,  3.73425990e-01,  6.83310032e-02, -8.48437011e-01])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_indcomp[1384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sidedchest\n",
      "anddyspnea\n",
      "andchest\n",
      "ofchest\n",
      "ofdyspnea\n",
      "leftchest\n",
      "anteriorchest\n",
      "paindyspnea\n",
      "pleuriticchest\n",
      "onsetdyspnea\n",
      "midsternalchest\n",
      "midlinechest\n",
      "worseningdyspnea\n",
      "posteriorchest\n",
      "substernalchest\n",
      "onsetchest\n",
      "'t\n",
      "rightchest\n",
      "compari\n",
      "lowerchest\n",
      "ecf\n",
      "aam\n",
      "hemopytosis\n",
      "increasingdyspnea\n",
      "bangladesh\n",
      "nonprod\n",
      "cought\n",
      "burmese\n",
      "ealier\n",
      "doesn\n",
      "melonoma\n",
      "66yof\n",
      "membranoproliferative\n",
      "burshechest\n",
      "ramicade\n",
      "lbot\n",
      "pkd\n",
      "xol\n",
      "sfhhc\n",
      "acacerbati\n",
      "chronicdyspnea\n",
      "54yof\n",
      "53yof\n",
      "circumcision\n",
      "anchest\n",
      "persistentdyspnea\n",
      "34yof\n",
      "outsidechest\n",
      "diffusechest\n",
      "increaseddyspnea\n",
      "hyperlidemia\n",
      "exsmoker\n",
      "experiencingdyspnea\n",
      "emphysemia\n",
      "denisities\n",
      "andshortness\n",
      "30yof\n",
      "odyspnea\n",
      "migranes\n",
      "''s\n",
      "immunosuppre\n",
      "centralchest\n",
      "50chest\n",
      "occasionalchest\n",
      "10lb\n",
      "painchest\n",
      "focalchest\n",
      "roomate\n",
      "hasn\n",
      "mitomyopathy\n",
      "painting\n",
      "pdp\n",
      "costochondralchest\n",
      "59chest\n",
      "insuffcieny\n",
      "forchest\n",
      "dyspneachest\n",
      "fwc\n",
      "bodyaches\n",
      "exertionaldyspnea\n",
      "somechest\n",
      "vhr\n",
      "occasionaldyspnea\n",
      "unspecchest\n",
      "sfwp\n",
      "30p\n",
      "fordyspnea\n",
      "transp\n",
      "exertionalchest\n",
      "positvie\n",
      "31yof\n",
      "60y\n",
      "009\n",
      "007\n",
      "hch\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "## Words not present in RADGLOVE\n",
    "tot = 0\n",
    "list = []\n",
    "for i in range(0,len(embedding_matrix_indcomp)):\n",
    "    if ((embedding_matrix_indcomp[i].all()==0)):\n",
    "        tot+=1\n",
    "        list.append(i)\n",
    "\n",
    "for key, value in tk_indcomp.word_index.items() :\n",
    "    if value in list:\n",
    "        print (key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "            \n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AttentionWeightedAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWeightedAverage(Layer):\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self._trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / K.sum(ai, axis=1, keepdims=True)\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'return_attention': self.return_attention })\n",
    "        return config\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, tuple):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image feature extractor model\n",
    "inputs1 = Input(shape=(512,))\n",
    "image_layer = Dropout(0.1)(inputs1)\n",
    "image_layer = Dense(128, activation=\"relu\")(image_layer)\n",
    "\n",
    "# Comparison model\n",
    "inputs3 = Input(shape=(MAX_WORDS_COMPARISON,))\n",
    "se3 = Embedding(vocab_size_indcomp, 100, mask_zero=True)(inputs3)\n",
    "se3 = Dropout(0.1)(se3)\n",
    "comparison_layer = GRU(128, recurrent_initializer='glorot_uniform')(se3)\n",
    "\n",
    "# Indication model\n",
    "inputs4 = Input(shape=(MAX_WORDS_INDICATION,))\n",
    "se5 = Embedding(vocab_size_indcomp, 100, mask_zero=True)(inputs4)\n",
    "se5 = Dropout(0.1)(se5)\n",
    "indication_layer = GRU(128, recurrent_initializer='glorot_uniform')(se5)\n",
    "\n",
    "# Findings model\n",
    "inputs2 = Input(shape=(MAX_SENT_LENGTH,))\n",
    "se1 = Embedding(vocab_size_find, 100, mask_zero=False)(inputs2)\n",
    "se1 = Dropout(0.2)(se1)\n",
    "se2 = Bidirectional(LSTM(512, recurrent_initializer='glorot_uniform', return_sequences=True))(se1)\n",
    "#se2 = BatchNormalization()(se2)\n",
    "se2 = TimeDistributed(Dense(512,activation='relu')) (se2)\n",
    "avg_pool = GlobalAveragePooling1D()(se2)\n",
    "max_pool = GlobalMaxPooling1D()(se2)\n",
    "attn = AttentionWeightedAverage()(se2)\n",
    "se2 = concatenate([attn, avg_pool, max_pool])\n",
    "#se2 = concatenate([avg_pool, max_pool])\n",
    "#se2 = RepeatVector(MAX_SENT_LENGTH) (se2)\n",
    "#se2 = Attention(MAX_SENT_LENGTH) (se2)\n",
    "#se2 = Bidirectional(GRU(512, recurrent_initializer='glorot_uniform', return_sequences=True))(se2)\n",
    "findings_layer = Dropout(0.2) (se2)\n",
    "findings_layer = Dense(128, activation=\"relu\")(findings_layer)\n",
    "\n",
    "# decoder (feed forward) model\n",
    "decoder1 = add([image_layer, comparison_layer, indication_layer, findings_layer])\n",
    "# decoder1 = Dense(512, activation=\"relu\")(decoder1)\n",
    "outputs = Dense(vocab_size_find, activation='softmax')(decoder1)\n",
    "\n",
    "# merge the two input models\n",
    "final_model = Model(inputs=[inputs1, inputs3, inputs4, inputs2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 75, 100)      150000      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 75, 100)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 75, 1024)     2510848     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 75, 512)      524800      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average (Att (None, 512)          512         time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 512)          0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 512)          0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 7, 100)       138500      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 100)       138500      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1536)         0           attention_weighted_average[0][0] \n",
      "                                                                 global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 100)       0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5, 100)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1536)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          65664       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 128)          88320       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 128)          88320       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          196736      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128)          0           dense[0][0]                      \n",
      "                                                                 gru[0][0]                        \n",
      "                                                                 gru_1[0][0]                      \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1500)         193500      add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 4,095,700\n",
      "Trainable params: 4,095,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_find.tolist().pop(0)\n",
    "embedding_matrix_indcomp.tolist().pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_find = np.array(embedding_matrix_find)\n",
    "embedding_matrix_indcomp = np.array(embedding_matrix_indcomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Freezing weights of embedding layers and compiling the model\n",
    "for i in [1]:   ## Findings layer\n",
    "    final_model.layers[i].set_weights([embedding_matrix_find])\n",
    "    final_model.layers[i].trainable = False\n",
    "    \n",
    "for i in [11,12]:   ## Indication/comparison layer\n",
    "    final_model.layers[i].set_weights([embedding_matrix_indcomp])\n",
    "    final_model.layers[i].trainable = False\n",
    "\n",
    "opt = Adam(0.001)\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the features and labels\n",
    "X1_image_train, X1_image_test, X2_comp_train, X2_comp_test, X3_ind_train, X3_ind_test, X4_find_train, X4_find_test, Y_find_train, Y_find_test = train_test_split(X1_image, X2_comp, X3_ind, X4_find, Y_find, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoint callback\n",
    "#filepath = 'modelgru99v1-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "filepath = 'model-ep{epoch:03d}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n",
    "                             save_best_only=False, save_weights_only=False, mode='auto', save_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "330/330 [==============================] - 5378s 16s/step - loss: 1.8999 - accuracy: 0.6571 - val_loss: 1.4624 - val_accuracy: 0.7119\n",
      "Epoch 2/5\n",
      "330/330 [==============================] - 4694s 14s/step - loss: 1.2276 - accuracy: 0.7506 - val_loss: 1.0494 - val_accuracy: 0.7854\n",
      "Epoch 3/5\n",
      "330/330 [==============================] - 5092s 15s/step - loss: 0.9746 - accuracy: 0.7943 - val_loss: 0.9273 - val_accuracy: 0.8108\n",
      "Epoch 4/5\n",
      "330/330 [==============================] - 5160s 16s/step - loss: 0.8418 - accuracy: 0.8167 - val_loss: 0.8518 - val_accuracy: 0.8244\n",
      "Epoch 5/5\n",
      " 50/330 [===>..........................] - ETA: 1:14:45 - loss: 0.7473 - accuracy: 0.8318"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-cd3ef456bbdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1_image_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2_comp_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX3_ind_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX4_find_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_find_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1_image_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2_comp_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX3_ind_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX4_find_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_find_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    804\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    798\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1211\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m   \u001b[1;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2584\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2585\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2587\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2945\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[1;31m# such as loss scaling and gradient clipping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n\u001b[1;32m--> 757\u001b[1;33m               self.trainable_variables)\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_minimize\u001b[1;34m(strategy, tape, optimizer, loss, trainable_variables)\u001b[0m\n\u001b[0;32m   2720\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scaled_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2722\u001b[1;33m   \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m   \u001b[1;31m# Whether to aggregate gradients outside of optimizer. This requires support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1689\u001b[0m   \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1691\u001b[1;33m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1692\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5618\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5619\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5620\u001b[1;33m         transpose_b)\n\u001b[0m\u001b[0;32m   5621\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5622\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = final_model.fit([np.array(X1_image_train),np.array(X2_comp_train),np.array(X3_ind_train),np.array(X4_find_train)],np.array(Y_find_train), epochs=5, verbose=1,callbacks=[checkpoint], validation_data=([np.array(X1_image_test), np.array(X2_comp_test), np.array(X3_ind_test), np.array(X4_find_test)], np.array(Y_find_test)), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making word to idx & idx to word\n",
    "ixtoword = {}\n",
    "wordtoix = {}\n",
    "\n",
    "ix = 1\n",
    "for w in tk_find.word_index:\n",
    "    wordtoix[w] = ix\n",
    "    ixtoword[ix] = w\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_find.word_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_search(model, cxr, comp, indication):\n",
    "    in_text = '<start>'\n",
    "    for i in range(MAX_SENT_LENGTH):\n",
    "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
    "        sequence = pad_sequences([sequence], maxlen=MAX_SENT_LENGTH)\n",
    "        yhat = model.predict([cxr, comp, indication,sequence], verbose=0)\n",
    "        res = np.argmax(yhat)\n",
    "        if res == 0:\n",
    "            res = np.argsort(yhat)[-2:].tolist()[0]\n",
    "            res = res[-2]\n",
    "            #print(res.index(h.nlargest(2,res)[-1]))\n",
    "            #yhat = res.index(h.nlargest(2,res)[-1])\n",
    "            #print(yhat)\n",
    "            word = ixtoword[res]\n",
    "        else:\n",
    "            word = ixtoword[res]\n",
    "        in_text += ' ' + word\n",
    "        if word == '<end>':\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load models\n",
    "pred_models = [\"G://acra/model-ep004.h5\"]\n",
    "#pred_models = [\"G://acra/modelgru99v1-ep008-loss0.485-val_loss0.739.h5\"]\n",
    "pred_model_values = [x[-12:-3] for x in pred_models]   ## For column names in prediction dataframe\n",
    "model_to_use = []\n",
    "\n",
    "for i in range(0,len(pred_models)):\n",
    "    model_to_use.append(load_model(pred_models[i], custom_objects={'AttentionWeightedAverage': AttentionWeightedAverage}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 30, 83, 179, 180, 2339, 2977, 3177], dtype='int64')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting IDs of random CXRs for prediction\n",
    "ids = [\"CXR1\",\"CXR1027\",\"CXR694\",\"CXR1082\",\"CXR1190\",\"CXR3595\",\"CXR910\"]\n",
    "id_index = df[df[\"ID\"].isin(ids)].index\n",
    "id_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mActual Findings\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the cardiac silhouette and mediastinum size are within normal limits. there is no pulmonary edema. there is no focal consolidation. there are no of a pleural effusion. there is no evidence of pneumothorax']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Predicted Findings 0\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the heart is normal in size the mediastinum is unremarkable the lungs are clear'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>del-ep004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU1</th>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU2</th>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU3</th>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU4</th>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       del-ep004\n",
       "BLEU1      0.198\n",
       "BLEU2      0.177\n",
       "BLEU3      0.147\n",
       "BLEU4      0.123"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mActual Findings\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['this examination is somewhat limited secondary to obscuration of the bilateral posterior costophrenic sulci on the lateral view. the cardiomediastinal silhouette is within normal limits for appearance. no focal areas of pulmonary consolidation. no pneumothorax. no large pleural effusion. the thoracic spine appears intact']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Predicted Findings 0\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the cardiomediastinal silhouette is normal in size and contour no focal consolidation pneumothorax or pleural effusion no acute bony abnormality'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>del-ep004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU1</th>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU2</th>\n",
       "      <td>0.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU3</th>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU4</th>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       del-ep004\n",
       "BLEU1      0.288\n",
       "BLEU2      0.276\n",
       "BLEU3      0.248\n",
       "BLEU4      0.227"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mActual Findings\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stable cardiomegaly. stable tortuosity of the aorta. no focal airspace opacities, pneumothorax or pleural effusion. mild degenerative changes of the thoracic spine']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Predicted Findings 0\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the heart is normal in size the mediastinum is unremarkable the lungs are clear without evidence of infiltrate there is no pneumothorax or effusion'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>del-ep004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU1</th>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU2</th>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU3</th>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU4</th>\n",
       "      <td>0.369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       del-ep004\n",
       "BLEU1      0.775\n",
       "BLEU2      0.593\n",
       "BLEU3      0.458\n",
       "BLEU4      0.369"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mActual Findings\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['both lungs are clear and expanded. heart and mediastinum normal']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Predicted Findings 0\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the heart is normal in size the mediastinum is unremarkable the lungs are clear'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>del-ep004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU1</th>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU2</th>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU3</th>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU4</th>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       del-ep004\n",
       "BLEU1      0.671\n",
       "BLEU2      0.587\n",
       "BLEU3      0.539\n",
       "BLEU4      0.503"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mActual Findings\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['both lungs are clear and expanded. heart and mediastinum normal']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Predicted Findings 0\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the heart is normal in size the mediastinum is unremarkable the lungs are clear'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>del-ep004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU1</th>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU2</th>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU3</th>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU4</th>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       del-ep004\n",
       "BLEU1      0.671\n",
       "BLEU2      0.587\n",
       "BLEU3      0.539\n",
       "BLEU4      0.503"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mActual Findings\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stable cardiomegaly and mediastinal contour. increased interstitial lung markings are seen, possibly due to volume overload. there is improved aeration of the lung bases with small residual left basilar effusion. no focal consolidation or pneumothorax. stable tunneled dialysis catheter. visualized osseous structures appear intact']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Predicted Findings 0\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the cardiomediastinal silhouette is normal in size and contour there is no focal airspace disease pneumothorax or pleural effusion there are no typical findings of pulmonary edema'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>del-ep004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU1</th>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU2</th>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU3</th>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU4</th>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       del-ep004\n",
       "BLEU1      0.428\n",
       "BLEU2      0.382\n",
       "BLEU3      0.313\n",
       "BLEU4      0.263"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mActual Findings\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the cardiac silhouette and pulmonary vascularity are normal. the lungs are clear. there is no evidence of pleural effusion. postoperative changes are noted in the mediastinum and lower cervical spine']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Predicted Findings 0\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the cardiomediastinal silhouette is normal in size and contour there is no pneumothorax or pleural effusion there is no focal air space opacity to suggest a pneumonia'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>del-ep004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU1</th>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU2</th>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU3</th>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU4</th>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       del-ep004\n",
       "BLEU1      0.775\n",
       "BLEU2      0.657\n",
       "BLEU3      0.547\n",
       "BLEU4      0.470"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\narayanan\\anaconda3\\envs\\acra\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mActual Findings\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the heart size is moderately enlarged. there is evidence of previous aortic valve replacement. sternotomy are grossly intact. the pulmonary and mediastinum are within normal limits. there is no pleural effusion or pneumothorax. there are chronically increased interstitial lung markings without superimposed focal airspace disease identified. there are degenerative changes of the spine']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Predicted Findings 0\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the heart is normal in size the mediastinum is unremarkable there is no pleural effusion or pneumothorax there is no acute bony abnormality'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>del-ep004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU1</th>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU2</th>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU3</th>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU4</th>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       del-ep004\n",
       "BLEU1      0.165\n",
       "BLEU2      0.155\n",
       "BLEU3      0.139\n",
       "BLEU4      0.127"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for loop in range(len(id_index)):\n",
    "    ## Prediction pipeline\n",
    "    #n=5  ## Give the index of the prediction CXR from above\n",
    "    idx = id_index[loop]  ## Image UID to print\n",
    "\n",
    "    ## Input features\n",
    "    pred_cxr = image_features_final[idx]\n",
    "    pred_indication = indication_vector[idx]\n",
    "    pred_comparison = comparison_vector[idx]\n",
    "\n",
    "\n",
    "    #print(pred_cxr)\n",
    "    #print(pred_comparison)\n",
    "    #print(pred_indication)\n",
    "\n",
    "\n",
    "    predicted_sent = []\n",
    "\n",
    "    for i in range(0,len(pred_models)):\n",
    "        ## Predicted findings\n",
    "        predicted_sent.append(pred_search(model_to_use[i], pred_cxr, pred_comparison, pred_indication))\n",
    "\n",
    "\n",
    "    ## Printing actual vs predicted\n",
    "    print (start+\"Actual Findings\"+end)\n",
    "    actual_findings = findings_sent[idx]\n",
    "    actual_findings = [w.replace('<start> ', '') for w in actual_findings]\n",
    "    actual_findings = [w.replace(' <end>', '') for w in actual_findings]\n",
    "    actual_findings\n",
    "\n",
    "    for i in range(0,len(predicted_sent)):\n",
    "        predicted_findings = predicted_sent[i].replace(\" <unk>\", \"\")\n",
    "        print (start+\"\\nPredicted Findings \"+str(i)+end)\n",
    "        predicted_findings\n",
    "\n",
    "    ## Calculating BLEU scores\n",
    "    weights = [(1.0/1.0, ), (1.0/2.0, 1.0/2.0,), (1.0/3.0, 1.0/3.0, 1.0/3.0,), (1.0/4.0, 1.0/4.0, 1.0/4.0, 1.0/4.0)]\n",
    "    scores = [[] for i in range(len(predicted_sent))]\n",
    "\n",
    "    weights = [(1.0/1.0, ), (1.0/2.0, 1.0/2.0,), (1.0/3.0, 1.0/3.0, 1.0/3.0,), (1.0/4.0, 1.0/4.0, 1.0/4.0, 1.0/4.0)]\n",
    "    scores = [[] for i in range(len(predicted_sent))]\n",
    "\n",
    "    for i in range(0, len(predicted_sent)):\n",
    "        for j in (weights):\n",
    "            scores[i].append(round(sentence_bleu(actual_findings,predicted_sent[i], j),3))\n",
    "\n",
    "    index = [\"BLEU1\", \"BLEU2\", \"BLEU3\", \"BLEU4\"]\n",
    "    pd.DataFrame(scores,columns=index,index=pred_model_values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(image_features_final,open('image_features_final.pkl','wb'))\n",
    "pickle.dump(indication_vector,open('indication_vector.pkl','wb'))\n",
    "pickle.dump(comparison_vector,open('comparison_vector.pkl','wb'))\n",
    "pickle.dump(Y_find,open('Y_find.pkl','wb'))\n",
    "pickle.dump(tk_find,open('tk_find.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
